{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_words(text):\n",
    "    # split into words by white space\n",
    "    words = text.split()\n",
    "    return words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    stripped = [re_punc.sub('', w) for w in words]\n",
    "    return stripped\n",
    "\n",
    "def keep_alphabetic(words):\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    return words\n",
    "\n",
    "def to_sentence(words):\n",
    "    # join words to a sentence\n",
    "    return ' '.join(words)\n",
    "\n",
    "def tweet(words):\n",
    "    tweet_tokenizer = nltk.tokenize.TweetTokenizer(strip_handles=True,reduce_len=True)\n",
    "    tweet = tweet_tokenizer.tokenize(words)\n",
    "    return tweet\n",
    "    \n",
    "\n",
    "def denoise_text(text):\n",
    "        words = split_into_words(text)\n",
    "        words = remove_punctuation(words)\n",
    "        words = keep_alphabetic(words)\n",
    "        return to_sentence(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "-  I believe everyone has a role to play in addressing climate change Whether an entrepreneur an inventor or consumer we can all help avoid a climate disaster\n",
      "____________________________\n",
      "['#climatechange', '#COP27']\n",
      "-  When it comes to alleviating the impacts of climatechange on smallholder farmers the goal should not simply be giving more food aid It should be to ensure no aid is needed in the first place\n",
      "____________________________\n",
      "[]\n",
      "-  Those of us who have done the most to cause this problem should help the rest of the world survive it We owe them that much\n",
      "____________________________\n",
      "['#WorldPneumoniaDay']\n",
      "-  More than children die from pneumonia every year Inventprise is working to change that WorldPneumoniaDay\n",
      "____________________________\n",
      "[]\n",
      "-  While the last steps are proving to be the toughest optimistic we will eradicate polio I recently visited Rega Institute where testing preventative medicine an important step toward a poliofree world\n",
      "____________________________\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../tweet.csv')\n",
    "for text in df['Tweets']:\n",
    "    splitted_text=text.split()\n",
    "    hashtag = [word for word in splitted_text if word.startswith(\"#\")]    \n",
    "    print(hashtag)\n",
    "\n",
    "    # #Removing the noisy text\n",
    "    print('- ',denoise_text(text))\n",
    "    print('____________________________')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac99e0caff889c9ddc34c1516b34ac6687d5cea80a6774b37948dcbb41c8e230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
